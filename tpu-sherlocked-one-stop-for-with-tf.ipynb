{"cells":[{"metadata":{},"cell_type":"markdown","source":"## You know my methods, Watson\n![](https://i.imgur.com/xy6FyyK.png)\n\nWith the pace at which deep learning is advancing it is becoming important and useful to be able to experiment with multiple models, ideas, approaches and potential solutions at a rapid pace. One of the methods of trying out various experiments is to **templatize code** and add **numerous levers** that can be played around with. This notebook aims to showcase one such structure for this.\n\nI will be demonstrating how you can setup a basic framework of building blocks and functions to very quickly iterate through a lot of ideas. The dataset used is from the [Contradictory, My Dear Watson](https://www.kaggle.com/c/contradictory-my-dear-watson) competition and the scope is limited to the [HuggingFace models with Tensorflow](https://huggingface.co/models?filter=tf).\n\nThis notebook is a skeletal experimental setup (which is not necessarily the best) but I strongly believe that every individual will have their own preferences and methods so it would work even better to tweak this notebook to your own taste and liking. There are a lot of elements that can be added and improved during the course of any competition or project.\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Packages\nInstall and import all the required packages and modules.\n","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-output":true,"_kg_hide-input":true},"cell_type":"code","source":"## installing the latest transformers version from pip\n!pip install transformers==3.0.2\nimport transformers\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"## importing packages\nimport gc\nimport os\nimport random\nimport transformers\nimport warnings\n\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport tensorflow.keras.backend as K\n\nfrom pathlib import Path\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import StratifiedKFold\nfrom tensorflow.keras import Model\nfrom tensorflow.keras.layers import Input, Dense\nfrom tensorflow.keras.losses import SparseCategoricalCrossentropy\nfrom tensorflow.keras.optimizers import Adam\nfrom transformers import AutoTokenizer, TFAutoModel\n\nprint(f\"TensorFlow version: {tf.__version__}\")\nprint(f\"Transformers version: {transformers.__version__}\")\n\nwarnings.filterwarnings(\"ignore\")\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Configuration\nThis is the most important section of the notebook. The configuration class is setup to define as many levers required for experiments as possible. It is meant to experiment on the following:\n\n* Different Huggingface models with Tensorflow\n* Different hyper-parameter spaces for models\n* Different seeds, splits, accelerators\n* Different learning rates (WIP)\n* Different augmentations (WIP)\n\nAnd all of this is possible just by changing one line of code!\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"## defining configuration\nclass Configuration():\n    \"\"\"\n    All configuration for running an experiment\n    \"\"\"\n    def __init__(\n        self,\n        model_name,\n        max_length = 64,\n        padding = True,\n        batch_size = 128,\n        epochs = 5,\n        metrics = [\"sparse_categorical_accuracy\"],\n        verbose = 1,\n        train_splits = 5,\n        accelerator = \"TPU\",\n        myluckynumber = 13\n    ):\n        # seed and accelerator\n        self.SEED = myluckynumber\n        self.ACCELERATOR = accelerator\n\n        # paths\n        self.PATH_TRAIN = Path(\"/kaggle/input/contradictory-my-dear-watson/train.csv\")\n        self.PATH_TEST  = Path(\"/kaggle/input/contradictory-my-dear-watson/test.csv\")\n\n        # splits\n        self.TRAIN_SPLITS = train_splits\n\n        # mapping of language\n        self.LANGUAGE_MAP = {\n            \"English\"   : 0,\n            \"Chinese\"   : 1,\n            \"Arabic\"    : 2,\n            \"French\"    : 3,\n            \"Swahili\"   : 4,\n            \"Urdu\"      : 5,\n            \"Vietnamese\": 6,\n            \"Russian\"   : 7,\n            \"Hindi\"     : 8,\n            \"Greek\"     : 9,\n            \"Thai\"      : 10,\n            \"Spanish\"   : 11,\n            \"German\"    : 12,\n            \"Turkish\"   : 13,\n            \"Bulgarian\" : 14\n        }\n\n        self.INVERSE_LANGUAGE_MAP = {v: k for k, v in self.LANGUAGE_MAP.items()}\n\n        # model configuration\n        self.MODEL_NAME = model_name\n        self.TOKENIZER = AutoTokenizer.from_pretrained(self.MODEL_NAME)\n\n        # model hyperparameters\n        self.MAX_LENGTH = max_length\n        self.PAD_TO_MAX_LENGTH = padding\n        self.BATCH_SIZE = batch_size\n        self.EPOCHS = epochs\n        self.METRICS = metrics\n        self.VERBOSE = verbose\n        \n        # initializing accelerator\n        self.initialize_accelerator()\n        \n    def initialize_accelerator(self):\n        \"\"\"\n        Initializing accelerator\n        \"\"\"\n        # checking TPU first\n        if self.ACCELERATOR == \"TPU\":\n            print(\"Connecting to TPU\")\n            try:\n                tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n                print(f\"Running on TPU {tpu.master()}\")\n            except ValueError:\n                print(\"Could not connect to TPU\")\n                tpu = None\n\n            if tpu:\n                try:\n                    print(\"Initializing TPU\")\n                    tf.config.experimental_connect_to_cluster(tpu)\n                    tf.tpu.experimental.initialize_tpu_system(tpu)\n                    self.strategy = tf.distribute.experimental.TPUStrategy(tpu)\n                    self.tpu = tpu\n                    print(\"TPU initialized\")\n                except _:\n                    print(\"Failed to initialize TPU\")\n            else:\n                print(\"Unable to initialize TPU\")\n                self.ACCELERATOR = \"GPU\"\n\n        # default for CPU and GPU\n        if self.ACCELERATOR != \"TPU\":\n            print(\"Using default strategy for CPU and single GPU\")\n            self.strategy = tf.distribute.get_strategy()\n\n        # checking GPUs\n        if self.ACCELERATOR == \"GPU\":\n            print(f\"GPUs Available: {len(tf.config.experimental.list_physical_devices('GPU'))}\")\n\n        # defining replicas\n        self.AUTO = tf.data.experimental.AUTOTUNE\n        self.REPLICAS = self.strategy.num_replicas_in_sync\n        print(f\"REPLICAS: {self.REPLICAS}\")\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Preparation\nPreprocessing the textual data as well as tokenizing it into the encoding format for the model.   \nFinally the data is converted into a tf.data.Dataset so that it works seamlessly across accelerators.\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"## data preparation functions\ndef encode_text(df, tokenizer, max_len, padding):\n    \"\"\"\n    Preprocessing textual data into encoded tokens\n    \"\"\"\n    text = df[[\"premise\", \"hypothesis\"]].values.tolist()\n\n    # encoding text using tokenizer of the model\n    text_encoded = tokenizer.batch_encode_plus(\n        text,\n        pad_to_max_length = padding,\n        max_length = max_len\n    )\n\n    return text_encoded\n\n\ndef get_tf_dataset(X, y, auto, labelled = True, repeat = False, shuffle = False, batch_size = 128):\n    \"\"\"\n    Creating tf.data.Dataset for TPU\n    \"\"\"\n    if labelled:\n        ds = (tf.data.Dataset.from_tensor_slices((X[\"input_ids\"], y)))\n    else:\n        ds = (tf.data.Dataset.from_tensor_slices(X[\"input_ids\"]))\n\n    if repeat:\n        ds = ds.repeat()\n\n    if shuffle:\n        ds = ds.shuffle(2048)\n\n    ds = ds.batch(batch_size)\n    ds = ds.prefetch(auto)\n\n    return ds\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Deep Learning model architecture\nDefining the deep learning network architecture along with the model configuration.\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"## building model\ndef build_model(model_name, max_len, metrics):\n    \"\"\"\n    Building the Deep Learning architecture\n    \"\"\"\n    # defining encoded inputs\n    input_ids = Input(shape = (max_len,), dtype = tf.int32, name = \"input_ids\")\n    \n    # defining transformer model embeddings\n    transformer_model = TFAutoModel.from_pretrained(model_name)\n    transformer_embeddings = transformer_model(input_ids)[0]\n    \n    # defining output layer\n    output_values = Dense(3, activation = \"softmax\")(transformer_embeddings[:, 0, :])\n\n    # defining model\n    model = Model(inputs = input_ids, outputs = output_values)\n    opt = Adam(learning_rate = 1e-5)\n    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True)\n    metrics = metrics\n\n    model.compile(optimizer = opt, loss = loss, metrics = metrics)\n\n    return model\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Stratified K-Fold Modelling\nThe model is run by splitting the training data into k-fold stratified on language and label. The function returns the out-of-fold train data predictions as well as the fold-averaged test predictions which can further conveniently be used for blending and stacking.\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"## stratified k-fold over language and label\ndef run_model(config):\n    \"\"\"\n    Running the model\n    \"\"\"\n    ## reading data\n    df_train = pd.read_csv(config.PATH_TRAIN)\n    df_test = pd.read_csv(config.PATH_TEST)\n\n    # adding column for stratified splitting\n    df_train[\"language_label\"] = df_train.language.astype(str) + \"_\" + df_train.label.astype(str)\n\n    # stratified K-fold on language and label\n    skf = StratifiedKFold(n_splits = config.TRAIN_SPLITS, shuffle = True, random_state = config.SEED)\n\n    # initializing predictions\n    preds_oof = np.zeros((df_train.shape[0], 3))\n    preds_test = np.zeros((df_test.shape[0], 3))\n    acc_oof = []\n\n    # iterating over folds\n    for (fold, (train_index, valid_index)) in enumerate(skf.split(df_train, df_train.language_label)):\n        # initializing TPU\n        if config.ACCELERATOR == \"TPU\":\n            if config.tpu:\n                config.initialize_accelerator()\n\n        # building model\n        K.clear_session()\n        with config.strategy.scope():\n            model = build_model(config.MODEL_NAME, config.MAX_LENGTH, config.METRICS)\n            if fold == 0:\n                print(model.summary())\n\n        print(\"\\n\")\n        print(\"#\" * 19)\n        print(f\"##### Fold: {fold + 1} #####\")\n        print(\"#\" * 19)\n\n        # splitting data into training and validation\n        X_train = df_train.iloc[train_index]\n        X_valid = df_train.iloc[valid_index]\n\n        y_train = X_train.label.values\n        y_valid = X_valid.label.values\n\n        print(\"\\nTokenizing\")\n\n        # encoding text data using tokenizer\n        X_train_encoded = encode_text(df = X_train, tokenizer = config.TOKENIZER, max_len = config.MAX_LENGTH, padding = config.PAD_TO_MAX_LENGTH)\n        X_valid_encoded = encode_text(df = X_valid, tokenizer = config.TOKENIZER, max_len = config.MAX_LENGTH, padding = config.PAD_TO_MAX_LENGTH)\n\n        # creating TF Dataset\n        ds_train = get_tf_dataset(X_train_encoded, y_train, config.AUTO, repeat = True, shuffle = True, batch_size = config.BATCH_SIZE * config.REPLICAS)\n        ds_valid = get_tf_dataset(X_valid_encoded, y_valid, config.AUTO, batch_size = config.BATCH_SIZE * config.REPLICAS * 4)\n\n        n_train = X_train.shape[0]\n\n        if fold == 0:\n            X_test_encoded = encode_text(df = df_test, tokenizer = config.TOKENIZER, max_len = config.MAX_LENGTH, padding = config.PAD_TO_MAX_LENGTH)\n\n        # saving model at best accuracy epoch\n        sv = tf.keras.callbacks.ModelCheckpoint(\n            \"model.h5\",\n            monitor = \"val_sparse_categorical_accuracy\",\n            verbose = 0,\n            save_best_only = True,\n            save_weights_only = True,\n            mode = \"max\",\n            save_freq = \"epoch\"\n        )\n\n        print(\"\\nTraining\")\n\n        # training model\n        model_history = model.fit(\n            ds_train,\n            epochs = config.EPOCHS,\n            callbacks = [sv],\n            steps_per_epoch = n_train / config.BATCH_SIZE // config.REPLICAS,\n            validation_data = ds_valid,\n            verbose = config.VERBOSE\n        )\n\n        print(\"\\nValidating\")\n\n        # scoring validation data\n        model.load_weights(\"model.h5\")\n        ds_valid = get_tf_dataset(X_valid_encoded, -1, config.AUTO, labelled = False, batch_size = config.BATCH_SIZE * config.REPLICAS * 4)\n\n        preds_valid = model.predict(ds_valid, verbose = config.VERBOSE)\n        acc = accuracy_score(y_valid, np.argmax(preds_valid, axis = 1))\n\n        preds_oof[valid_index] = preds_valid\n        acc_oof.append(acc)\n\n        print(\"\\nInferencing\")\n\n        # scoring test data\n        ds_test = get_tf_dataset(X_test_encoded, -1, config.AUTO, labelled = False, batch_size = config.BATCH_SIZE * config.REPLICAS * 4)\n        preds_test += model.predict(ds_test, verbose = config.VERBOSE) / config.TRAIN_SPLITS\n\n        print(f\"\\nFold {fold + 1} Accuracy: {round(acc, 4)}\\n\")\n\n        g = gc.collect()\n\n    # overall CV score and standard deviation\n    print(f\"\\nCV Mean Accuracy: {round(np.mean(acc_oof), 4)}\")\n    print(f\"CV StdDev Accuracy: {round(np.std(acc_oof), 4)}\\n\")\n\n    return preds_oof, preds_test\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Experimenting with different models\nThe list of HuggingFace models with Tensorflow can be viewed here: https://huggingface.co/models?filter=tf   \nTrying out different models is as easy as a one-line change while creating the configuration. You can uncomment the different model codes and run the models.\n","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"# Model 1: Multilingual Bert Base Cased\n#config_1 = Configuration(\"bert-base-multilingual-cased\", max_length = 32, batch_size = 32, epochs = 2, train_splits = 2)\n#preds_train_1, preds_test_1 = run_model(config_1)\n\n# Model 2: Distilbert Base Uncased\n#config_2 = Configuration(\"distilbert-base-uncased\", max_length = 32, batch_size = 32, epochs = 2, train_splits = 2)\n#preds_train_2, preds_test_2 = run_model(config_2)\n\n# Model 3: XLM Roberta Base\n#config_3 = Configuration(\"jplu/tf-xlm-roberta-base\", max_length = 32, batch_size = 32, epochs = 2, train_splits = 2)\n#preds_train_3, preds_test_3 = run_model(config_3)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Tuning hyperparameters\nExperimenting with different hyperparameters only requires a one-line change while creating the configuration. You can uncomment the different hyperparameter spaces code and run the models.\n","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"# Hyperparameter Space 1\n#config_1 = Configuration(\"bert-base-multilingual-cased\", max_length = 32, batch_size = 32, epochs = 2, train_splits = 2)\n#preds_train_1, preds_test_1 = run_model(config_1)\n\n# Hyperparameter Space 2\n#config_2 = Configuration(\"bert-base-multilingual-cased\", max_length = 64, batch_size = 32, epochs = 3, train_splits = 2)\n#preds_train_2, preds_test_2 = run_model(config_2)\n\n# Hyperparameter Space 3\n#config_3 = Configuration(\"bert-base-multilingual-cased\", max_length = 84, batch_size = 16, epochs = 4, train_splits = 2)\n#preds_train_3, preds_test_3 = run_model(config_3)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Transitioning across accelerators\nRunning the models on TPU, GPU or CPU can be configured without changing any code.  \nNote that for running on TPU (or GPU), the corresponding Accelerator must be chosen in the Kaggle Notebook settings. You can uncomment the different accelerator codes and run the models.\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# TPU\n#config_1 = Configuration(\"bert-base-multilingual-cased\", max_length = 32, batch_size = 32, epochs = 2, train_splits = 2, accelerator = \"TPU\")\n#preds_train_1, preds_test_1 = run_model(config_1)\n\n# GPU\n#config_2 = Configuration(\"bert-base-multilingual-cased\", max_length = 32, batch_size = 32, epochs = 2, train_splits = 2, accelerator = \"GPU\")\n#preds_train_2, preds_test_2 = run_model(config_2)\n\n# CPU\n#config_3 = Configuration(\"bert-base-multilingual-cased\", max_length = 32, batch_size = 32, epochs = 2, train_splits = 2, accelerator = \"CPU\")\n#preds_train_3, preds_test_3 = run_model(config_3)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Final model\nBuilding final model after tuning hyperparameters.\n","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"# Final Model: XLM Roberta Large\nconfig_1 = Configuration(\"jplu/tf-xlm-roberta-large\", max_length = 84, batch_size = 32, epochs = 16, train_splits = 4)\npreds_train_1, preds_test_1 = run_model(config_1)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Submission\nCreating the submission file by predicting the label with highest probability.\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test = pd.read_csv(config_1.PATH_TEST)\n\ndf_submission = pd.DataFrame({\"id\": df_test.id.values, \"prediction\": np.argmax(preds_test_1, axis = 1)})\ndf_submission.to_csv(\"submission.csv\", index = False)\n\ndf_submission.prediction.value_counts()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Elementary, My Dear Watson\nThis is a bare skeletal workflow but as any competition progresses there will be new elements that would need to be added into the workflow and this process can help in scaling and iterating over experiments meticulously.\n\nHere are some open ideas to work on:\n\n* Adding data augmentation\n* Pre-processing text data before tokenization\n* Trying other models\n* Tuning hyperparameters\n* Ensembling multiple models\n\n**Good Luck!**\n","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}